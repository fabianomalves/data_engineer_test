{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Criar um ambiente virtual e instalar todos os pacotes Python, via pip install.\n","    Aqui é assumido que o python e o gerenciador de pacotes pip já estão \n","    instalados e funcionando em seu ambiente.\n","\n","\n","### Criando um ambiente virtual:\n","    python -m venv .venv\n","\n","### Ativando o ambiente virtual Python:\n","    source .venv/bin/activate\n","\n","### Os pacotes Python, podem ser instalados usando com requirements.txt, na mesma pasta do script:\n","    pip install -r requirements.txt"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"mNnFGS7WnLSJ"},"source":["## Importar bibliotecas que foram instaladas via pip\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2121,"status":"ok","timestamp":1671825778418,"user":{"displayName":"Fabiano Moreira Alves","userId":"09146577383397768685"},"user_tz":180},"id":"PVWw0Wj9PJgA","outputId":"2b07678d-d5b1-4635-c3c0-c25b3b91ae16"},"outputs":[],"source":["import requests\n","import json\n","import pandas as pd\n","from pandas.io.json import json_normalize\n","import numpy as np\n","import geopy\n","from geopy.geocoders import Nominatim\n","from geopy.point import Point\n","from cryptography.fernet import Fernet\n","from datetime import datetime\n","from google.oauth2.credentials import Credentials\n","from google.cloud import bigquery\n","from google.oauth2 import service_account\n","import pandas_gbq\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Gerar um token para acessar a API\n","    O token para acessar a API da begrowth é fornecido após cadastrar um\n","    usuário.\n","\n","    Informar os dados Nome e E-mail nos campos full_name e email.\n","    \n","    Após fazer um request, é retornado o usuário e o token para acessar a API.\n","    Por fim, imprime na tela o json obtido."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["headers = {\n","    'accept': 'application/json',\n","    'Content-Type': 'application/json',\n","}\n","\n","json_data = {\n","    'full_name': 'Fabiano Moreira Alves',\n","    'email': 'fabianomalves@proton.me',\n","}\n","\n","access_token = requests.post('https://begrowth.deta.dev/user/', headers=headers, json=json_data)\n","access_token_json = access_token.json()\n","\n","print(access_token_json)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"uzvfZ4d0nd3R"},"source":["## Separando o usuário e o token para acessar a API\n","    Como o request retorna um json(dicionário) é preciso separar o dicionário\n","    e pegar somente a informação do token.\n","    \n","    Após isso, imprime na tela somente o token."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":363,"status":"ok","timestamp":1671825786381,"user":{"displayName":"Fabiano Moreira Alves","userId":"09146577383397768685"},"user_tz":180},"id":"M6FJKmp5ndYr","outputId":"21863d33-2c6c-4cc3-d893-4e8055d478af"},"outputs":[],"source":["# split dictionary into keys and values\n","keys = []\n","values = []\n","items = access_token_json.items()\n","for item in items:\n","    keys.append(item[0]), values.append(item[1])\n"," \n","# printing keys and values separately\n","string_acess_token = str(values[-1])\n","print(string_acess_token)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"oGGQwQKqnsP5"},"source":["## Consumir a api, chamando-a e passando o token adquirido\n","    Concatenando a url https://begrowth.deta.dev/token=access_token, junto do\n","    token obtido é necessário para acessar os dados da API.\n","\n","    Para isso, concatenei a url com o token obtido anteriormente e salvei numa\n","    variável.\n","    \n","    Exibindo a url, concatenando com o token obtido."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":376,"status":"ok","timestamp":1671825950303,"user":{"displayName":"Fabiano Moreira Alves","userId":"09146577383397768685"},"user_tz":180},"id":"qIprVyn6nsky","outputId":"17674d07-665f-41dd-a235-6ec294c45934"},"outputs":[],"source":["url_dev = \"https://begrowth.deta.dev/token=\"\n","url_dev_with_token = url_dev + string_acess_token\n","print(url_dev_with_token)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"eenrX4tjlAY0"},"source":["## Normalizar o json recebido pelo request, inserindo ele num dataframe Pandas\n","    Como os dados do obtidos pelo requests são um json, \n","    foi feita uma \"normalização dos dados e foi inserido num dataframe.\n","\n","    Processo feito para trabalhar melhor com os dados, principalmente com campo\n","    address, que contem outro dicionário dentro da estrutura do json.\n","    \n","    Exibindo as primeiras linhas do dataframe."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4636,"status":"ok","timestamp":1671826012948,"user":{"displayName":"Fabiano Moreira Alves","userId":"09146577383397768685"},"user_tz":180},"id":"ugBTuX254B18","outputId":"ecc8f768-329f-4574-a3d4-420c4e1c3053"},"outputs":[],"source":["data = json.loads(requests.get(url_dev_with_token).text)\n","df_json_normalize = pd.json_normalize(data)\n","df_json_normalize.head()\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"VEGDyuOOWqwn"},"source":["## Procurando linhas duplicadas:\n","    Ao exibir as primeiras linhas do dataframe, já exibiam algumas linhas\n","    duplicadas. \n","    \n","    Filtrando os duplicados pelo id dos usuários e retornando \n","    todos os duplicados."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":354,"status":"ok","timestamp":1671826042149,"user":{"displayName":"Fabiano Moreira Alves","userId":"09146577383397768685"},"user_tz":180},"id":"KktpJsE0r8Ax","outputId":"a95a676b-fd4c-43c6-9e10-7a87a694222c"},"outputs":[],"source":["duplicate_rows = df_json_normalize[df_json_normalize.duplicated(['id', ])]\n","print(duplicate_rows)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"SKKBo_fojIQh"},"source":["## Removendo as linhas duplicadas\n","    Dando um drop nas linhas duplicadas, filtrando pelo 'id' e salvando\n","    em outro dataframe.\n","\n","    Depois exibe somente as linhas distintas."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":389,"status":"ok","timestamp":1671826105536,"user":{"displayName":"Fabiano Moreira Alves","userId":"09146577383397768685"},"user_tz":180},"id":"dmFKglkTh95r","outputId":"0b740df8-0822-4e85-9165-0058ebfc0ec9"},"outputs":[],"source":["df_distinct_id_rows = df_json_normalize.drop_duplicates(subset=['id'])\n","print(df_distinct_id_rows)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"kr7S58dq4B1-"},"source":["## Fazendo um reverse geocoding \n","    Após normalizar os dados, foram criados 3 novos campos, \n","    destrinchando o campo address. \n","\n","    Campos address.geo_latitude, address.geo_longitude, address.country.\n","\n","    Para conseguir a informação do estado, \n","    é necessário o processo de reverse geocoding, \n","    onde pegamos a latitude e longitude e filtramos as informações que queremos,\n","    no caso o estado. \n","    \n","    Porém, verifiquei que os nomes dos estados\n","    apresentam acentos, o que é um problema na hora de fazer os selects.\n","    \n","    Para isso, peguei o campo ISO 3166-2, que é um padrão mundial de siglas\n","    por estados, gerando o padrão BR-UF.\n","    Como teremos os UFs, será melhor para fazer os selects."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create a geocoder object using the Nominatim API\n","geolocator = Nominatim(user_agent=\"my_geocoder_state\")\n","\n","# Define a function to reverse geocode the state\n","def get_state(lat, lng):\n","  # Use the geocoder object to reverse geocode the coordinates\n","  location = geolocator.reverse((lat, lng))\n","  # Extract the state code from the response, using ISO3166-2-lvl4\n","  state = location.raw['address']['ISO3166-2-lvl4']\n","  return state\n","\n","# Apply the function to each row of the DataFrame and store the result in a new column\n","\n","df_distinct_id_rows.loc[:, ['address_state']] = df_distinct_id_rows.apply(lambda x: get_state(x['address.geo_latitude'], x['address.geo_longitude']), axis=1)\n","\n","\n","\n","# Display a resulting DataFrame\n","df_distinct_id_rows.head()\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Salvando o novo dataframe num arquivo csv.\n","    Como o processo de reverse geocodin demora demais, \n","    salvei o dataframe localmente, \n","    para não demorar muito, \n","    caso fosse necessário rodar novamente o script.\n","\n","    Conseguiria trabalhar desse ponto em diante com o arquivo fisico,\n","    caso necessário."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_distinct_id_rows.to_csv('../data_engineer_test/df_distinct_id_rows.csv', index=False)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Read csv file"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_distinct_id_rows = pd.read_csv('../data_engineer_test/df_distinct_id_rows.csv')\n","df_distinct_id_rows.head()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Descriptografar o campo CPF\n","    O campo CPF está criptografado, pela criptografia Fernet.\n","    \n","    Para isso, é necessário usar a chave Fernet, passada por e-mail.\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fernet = Fernet(b'ekkxXo0uHWRkIbHqHrLS4gaMj2hWTYMJyPTAbi9INGI=')\n","\n","df_distinct_id_rows['cpf'] = df_distinct_id_rows['cpf'].apply(lambda x: fernet.decrypt(x.encode()))\n","\n","df_distinct_id_rows.head()\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Salvando o arquivo descriptografado num csv"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","df_distinct_id_rows.to_csv('../data_engineer_test/df_decrypt_cpf.csv', index=False)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Lendo o arquivo csv, cujo cpf foi descriptografado."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_decrypt_cpf = pd.read_csv('../data_engineer_test/df_decrypt_cpf.csv' )\n","df_decrypt_cpf.head()\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Formatando a coluna CPF\n","    Após descriptografar o cpf, a coluna ficou um b de byte, \n","    oriundo da chave de descriptografar.\n","\n","    Fazendo a remoção das informações que são desnecessárias."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_decrypt_cpf['cpf'] = df_decrypt_cpf['cpf'].apply(lambda x: x[2: -1])\n","df_decrypt_cpf.head()\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Salvando o arquivo descriptografado e formatado num csv"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_decrypt_cpf.to_csv('../data_engineer_test/df_decrypt_formatting_cpf.csv', index=False)\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Lendo o arquivo csv, descriptografado e formatado e transformando num df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_decrypt_formatting_cpf = pd.read_csv('../data_engineer_test/df_decrypt_formatting_cpf.csv' )\n","df_decrypt_formatting_cpf.head()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Removendo o prefixo \"BR-\" da coluna address_state\n","    Para deixar a coluna mais clean, \n","    manter somente as UFs no campo address_state"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_decrypt_formatting_cpf[\"address_state\"] = df_decrypt_formatting_cpf[\"address_state\"].str.replace(\"BR-\", \"\")\n","df_decrypt_formatting_cpf.head()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Inserindo colunas dt_insert e candidate_name\n","    Inserindo as colunas dt_insert e candidate_name\n","    conforme solicitado e prenchendo com um timestamp e o nome."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create a variable now, with the actual timestamp\n","now = datetime.now()\n","\n","# Create new columns\n","df_decrypt_formatting_cpf = df_decrypt_formatting_cpf.assign(\n","    dt_insert=now,\n","    candidate_name='Fabiano Moreira Alves'\n",")\n","\n","df_decrypt_formatting_cpf.head()\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Alterar os nomes das colunas, inserindo um '_' ao invés de '.'\n","    Removendo os pontos dos nomes das colunas e trocando por underscores.\n","    Processo necessário para inseir os dados no Google BigQuery.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_decrypt_formatting_cpf = df_decrypt_formatting_cpf.rename(columns=lambda x: x.replace('.', '_'))\n","\n","df_decrypt_formatting_cpf.head()\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Salvando o dataframe após as transformações."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_decrypt_formatting_cpf.to_csv('../data_engineer_test/bg_data_enginner_test_fabiano.csv', index=False)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Create a service account with the key provided in email"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"ename":"ValueError","evalue":"This library only supports credentials from google-auth-library-python. See https://google-auth.readthedocs.io/en/latest/ for help on authentication with this library.","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[2], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39m# Load the service account key file\u001b[39;00m\n\u001b[1;32m     10\u001b[0m credentials \u001b[39m=\u001b[39m bigquery\u001b[39m.\u001b[39mClient\u001b[39m.\u001b[39mfrom_service_account_json(\u001b[39m'\u001b[39m\u001b[39m../data_engineer_test/svc-data-engineer-test.json\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m bg_data_enginner_test_fabiano\u001b[39m.\u001b[39;49mto_gbq(destination_table\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mproject_id\u001b[39m}\u001b[39;49;00m\u001b[39m.\u001b[39;49m\u001b[39m{\u001b[39;49;00mdataset_id\u001b[39m}\u001b[39;49;00m\u001b[39m.\u001b[39;49m\u001b[39m{\u001b[39;49;00mtable_id\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m, project_id\u001b[39m=\u001b[39;49mproject_id, if_exists\u001b[39m=\u001b[39;49mif_exists, credentials\u001b[39m=\u001b[39;49mcredentials)\n","File \u001b[0;32m~/Insync/fabiano.moreira.alves@gmail.com/Google Drive/Projects/data_engineer_test/.venv/lib/python3.10/site-packages/pandas/core/frame.py:2169\u001b[0m, in \u001b[0;36mDataFrame.to_gbq\u001b[0;34m(self, destination_table, project_id, chunksize, reauth, if_exists, auth_local_webserver, table_schema, location, progress_bar, credentials)\u001b[0m\n\u001b[1;32m   2084\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2085\u001b[0m \u001b[39mWrite a DataFrame to a Google BigQuery table.\u001b[39;00m\n\u001b[1;32m   2086\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2165\u001b[0m \u001b[39mread_gbq : Read a DataFrame from Google BigQuery.\u001b[39;00m\n\u001b[1;32m   2166\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2167\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m \u001b[39mimport\u001b[39;00m gbq\n\u001b[0;32m-> 2169\u001b[0m gbq\u001b[39m.\u001b[39;49mto_gbq(\n\u001b[1;32m   2170\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   2171\u001b[0m     destination_table,\n\u001b[1;32m   2172\u001b[0m     project_id\u001b[39m=\u001b[39;49mproject_id,\n\u001b[1;32m   2173\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[1;32m   2174\u001b[0m     reauth\u001b[39m=\u001b[39;49mreauth,\n\u001b[1;32m   2175\u001b[0m     if_exists\u001b[39m=\u001b[39;49mif_exists,\n\u001b[1;32m   2176\u001b[0m     auth_local_webserver\u001b[39m=\u001b[39;49mauth_local_webserver,\n\u001b[1;32m   2177\u001b[0m     table_schema\u001b[39m=\u001b[39;49mtable_schema,\n\u001b[1;32m   2178\u001b[0m     location\u001b[39m=\u001b[39;49mlocation,\n\u001b[1;32m   2179\u001b[0m     progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m   2180\u001b[0m     credentials\u001b[39m=\u001b[39;49mcredentials,\n\u001b[1;32m   2181\u001b[0m )\n","File \u001b[0;32m~/Insync/fabiano.moreira.alves@gmail.com/Google Drive/Projects/data_engineer_test/.venv/lib/python3.10/site-packages/pandas/io/gbq.py:218\u001b[0m, in \u001b[0;36mto_gbq\u001b[0;34m(dataframe, destination_table, project_id, chunksize, reauth, if_exists, auth_local_webserver, table_schema, location, progress_bar, credentials)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mto_gbq\u001b[39m(\n\u001b[1;32m    205\u001b[0m     dataframe: DataFrame,\n\u001b[1;32m    206\u001b[0m     destination_table: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    215\u001b[0m     credentials\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    216\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    217\u001b[0m     pandas_gbq \u001b[39m=\u001b[39m _try_import()\n\u001b[0;32m--> 218\u001b[0m     pandas_gbq\u001b[39m.\u001b[39;49mto_gbq(\n\u001b[1;32m    219\u001b[0m         dataframe,\n\u001b[1;32m    220\u001b[0m         destination_table,\n\u001b[1;32m    221\u001b[0m         project_id\u001b[39m=\u001b[39;49mproject_id,\n\u001b[1;32m    222\u001b[0m         chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[1;32m    223\u001b[0m         reauth\u001b[39m=\u001b[39;49mreauth,\n\u001b[1;32m    224\u001b[0m         if_exists\u001b[39m=\u001b[39;49mif_exists,\n\u001b[1;32m    225\u001b[0m         auth_local_webserver\u001b[39m=\u001b[39;49mauth_local_webserver,\n\u001b[1;32m    226\u001b[0m         table_schema\u001b[39m=\u001b[39;49mtable_schema,\n\u001b[1;32m    227\u001b[0m         location\u001b[39m=\u001b[39;49mlocation,\n\u001b[1;32m    228\u001b[0m         progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m    229\u001b[0m         credentials\u001b[39m=\u001b[39;49mcredentials,\n\u001b[1;32m    230\u001b[0m     )\n","File \u001b[0;32m~/Insync/fabiano.moreira.alves@gmail.com/Google Drive/Projects/data_engineer_test/.venv/lib/python3.10/site-packages/pandas_gbq/gbq.py:1127\u001b[0m, in \u001b[0;36mto_gbq\u001b[0;34m(dataframe, destination_table, project_id, chunksize, reauth, if_exists, auth_local_webserver, table_schema, location, progress_bar, credentials, api_method, verbose, private_key)\u001b[0m\n\u001b[1;32m   1123\u001b[0m dispositions_dict \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\u001b[39mzip\u001b[39m(if_exists_list, dispositions))\n\u001b[1;32m   1125\u001b[0m write_disposition \u001b[39m=\u001b[39m dispositions_dict[if_exists]\n\u001b[0;32m-> 1127\u001b[0m connector \u001b[39m=\u001b[39m GbqConnector(\n\u001b[1;32m   1128\u001b[0m     project_id,\n\u001b[1;32m   1129\u001b[0m     reauth\u001b[39m=\u001b[39;49mreauth,\n\u001b[1;32m   1130\u001b[0m     auth_local_webserver\u001b[39m=\u001b[39;49mauth_local_webserver,\n\u001b[1;32m   1131\u001b[0m     location\u001b[39m=\u001b[39;49mlocation,\n\u001b[1;32m   1132\u001b[0m     credentials\u001b[39m=\u001b[39;49mcredentials,\n\u001b[1;32m   1133\u001b[0m     private_key\u001b[39m=\u001b[39;49mprivate_key,\n\u001b[1;32m   1134\u001b[0m )\n\u001b[1;32m   1135\u001b[0m bqclient \u001b[39m=\u001b[39m connector\u001b[39m.\u001b[39mclient\n\u001b[1;32m   1137\u001b[0m destination_table_ref \u001b[39m=\u001b[39m bigquery\u001b[39m.\u001b[39mtable\u001b[39m.\u001b[39mTableReference\u001b[39m.\u001b[39mfrom_string(\n\u001b[1;32m   1138\u001b[0m     destination_table, default_project\u001b[39m=\u001b[39mconnector\u001b[39m.\u001b[39mproject_id\n\u001b[1;32m   1139\u001b[0m )\n","File \u001b[0;32m~/Insync/fabiano.moreira.alves@gmail.com/Google Drive/Projects/data_engineer_test/.venv/lib/python3.10/site-packages/pandas_gbq/gbq.py:330\u001b[0m, in \u001b[0;36mGbqConnector.__init__\u001b[0;34m(self, project_id, reauth, private_key, auth_local_webserver, dialect, location, credentials, use_bqstorage_api)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[39mif\u001b[39;00m context\u001b[39m.\u001b[39mproject \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    328\u001b[0m     context\u001b[39m.\u001b[39mproject \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproject_id\n\u001b[0;32m--> 330\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclient \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_client()\n\u001b[1;32m    331\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_bqstorage_api \u001b[39m=\u001b[39m use_bqstorage_api\n\u001b[1;32m    333\u001b[0m \u001b[39m# BQ Queries costs $5 per TB. First 1 TB per month is free\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[39m# see here for more: https://cloud.google.com/bigquery/pricing\u001b[39;00m\n","File \u001b[0;32m~/Insync/fabiano.moreira.alves@gmail.com/Google Drive/Projects/data_engineer_test/.venv/lib/python3.10/site-packages/pandas_gbq/gbq.py:366\u001b[0m, in \u001b[0;36mGbqConnector.get_client\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m\n\u001b[1;32m    363\u001b[0m client_info \u001b[39m=\u001b[39m google\u001b[39m.\u001b[39mapi_core\u001b[39m.\u001b[39mclient_info\u001b[39m.\u001b[39mClientInfo(\n\u001b[1;32m    364\u001b[0m     user_agent\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpandas-\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(pandas\u001b[39m.\u001b[39m__version__)\n\u001b[1;32m    365\u001b[0m )\n\u001b[0;32m--> 366\u001b[0m \u001b[39mreturn\u001b[39;00m bigquery\u001b[39m.\u001b[39;49mClient(\n\u001b[1;32m    367\u001b[0m     project\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mproject_id,\n\u001b[1;32m    368\u001b[0m     credentials\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcredentials,\n\u001b[1;32m    369\u001b[0m     client_info\u001b[39m=\u001b[39;49mclient_info,\n\u001b[1;32m    370\u001b[0m )\n","File \u001b[0;32m~/Insync/fabiano.moreira.alves@gmail.com/Google Drive/Projects/data_engineer_test/.venv/lib/python3.10/site-packages/google/cloud/bigquery/client.py:244\u001b[0m, in \u001b[0;36mClient.__init__\u001b[0;34m(self, project, credentials, _http, location, default_query_job_config, client_info, client_options)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m    235\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    236\u001b[0m     project\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    242\u001b[0m     client_options\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    243\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 244\u001b[0m     \u001b[39msuper\u001b[39;49m(Client, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m    245\u001b[0m         project\u001b[39m=\u001b[39;49mproject,\n\u001b[1;32m    246\u001b[0m         credentials\u001b[39m=\u001b[39;49mcredentials,\n\u001b[1;32m    247\u001b[0m         client_options\u001b[39m=\u001b[39;49mclient_options,\n\u001b[1;32m    248\u001b[0m         _http\u001b[39m=\u001b[39;49m_http,\n\u001b[1;32m    249\u001b[0m     )\n\u001b[1;32m    251\u001b[0m     kw_args \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mclient_info\u001b[39m\u001b[39m\"\u001b[39m: client_info}\n\u001b[1;32m    252\u001b[0m     bq_host \u001b[39m=\u001b[39m _get_bigquery_host()\n","File \u001b[0;32m~/Insync/fabiano.moreira.alves@gmail.com/Google Drive/Projects/data_engineer_test/.venv/lib/python3.10/site-packages/google/cloud/client/__init__.py:321\u001b[0m, in \u001b[0;36mClientWithProject.__init__\u001b[0;34m(self, project, credentials, client_options, _http)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, project\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, credentials\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, client_options\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, _http\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    320\u001b[0m     _ClientProjectMixin\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, project\u001b[39m=\u001b[39mproject, credentials\u001b[39m=\u001b[39mcredentials)\n\u001b[0;32m--> 321\u001b[0m     Client\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m    322\u001b[0m         \u001b[39mself\u001b[39;49m, credentials\u001b[39m=\u001b[39;49mcredentials, client_options\u001b[39m=\u001b[39;49mclient_options, _http\u001b[39m=\u001b[39;49m_http\n\u001b[1;32m    323\u001b[0m     )\n","File \u001b[0;32m~/Insync/fabiano.moreira.alves@gmail.com/Google Drive/Projects/data_engineer_test/.venv/lib/python3.10/site-packages/google/cloud/client/__init__.py:167\u001b[0m, in \u001b[0;36mClient.__init__\u001b[0;34m(self, credentials, _http, client_options)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[39mraise\u001b[39;00m google\u001b[39m.\u001b[39mapi_core\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mDuplicateCredentialArgs(\n\u001b[1;32m    161\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcredentials\u001b[39m\u001b[39m'\u001b[39m\u001b[39m and \u001b[39m\u001b[39m'\u001b[39m\u001b[39mclient_options.credentials_file\u001b[39m\u001b[39m'\u001b[39m\u001b[39m are mutually exclusive.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    162\u001b[0m     )\n\u001b[1;32m    164\u001b[0m \u001b[39mif\u001b[39;00m credentials \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\n\u001b[1;32m    165\u001b[0m     credentials, google\u001b[39m.\u001b[39mauth\u001b[39m.\u001b[39mcredentials\u001b[39m.\u001b[39mCredentials\n\u001b[1;32m    166\u001b[0m ):\n\u001b[0;32m--> 167\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(_GOOGLE_AUTH_CREDENTIALS_HELP)\n\u001b[1;32m    169\u001b[0m scopes \u001b[39m=\u001b[39m client_options\u001b[39m.\u001b[39mscopes \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mSCOPE\n\u001b[1;32m    171\u001b[0m \u001b[39m# if no http is provided, credentials must exist\u001b[39;00m\n","\u001b[0;31mValueError\u001b[0m: This library only supports credentials from google-auth-library-python. See https://google-auth.readthedocs.io/en/latest/ for help on authentication with this library."]}],"source":["bg_data_enginner_test_fabiano = pd.read_csv('../data_engineer_test/bg_data_enginner_test_fabiano.csv')\n","\n","project_id = \"begrowth-user-api-demo\"\n","dataset_id = \"bg_users\"\n","table_id = \"bg_data_enginner_test_fabiano\"\n","if_exists = \"replace\"\n","\n","\n","# Load the service account key file\n","credentials = bigquery.Client.from_service_account_json('../data_engineer_test/svc-data-engineer-test.json')\n","\n","bg_data_enginner_test_fabiano.to_gbq(destination_table=f\"{project_id}.{dataset_id}.{table_id}\", project_id=project_id, if_exists=if_exists, credentials=credentials)\n","\n","    "]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":".venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"vscode":{"interpreter":{"hash":"5b35418006b61e0b8845dba7655e90c821974852f2d4b880fdb488ffc5bd8e57"}}},"nbformat":4,"nbformat_minor":0}
