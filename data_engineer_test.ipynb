{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Criar um ambiente virtual e instalar todos os pacotes Python, via pip install.\n","    Aqui é assumido que o python e o gerenciador de pacotes pip já estão \n","    instalados e funcionando em seu ambiente.\n","\n","\n","### Criando um ambiente virtual:\n","    python -m venv .venv\n","\n","### Ativando o ambiente virtual Python:\n","    source .venv/bin/activate\n","\n","### Os pacotes Python, podem ser instalados usando com requirements.txt, na mesma pasta do script:\n","    pip install -r requirements.txt"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"mNnFGS7WnLSJ"},"source":["## Importar bibliotecas que foram instaladas via pip\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2121,"status":"ok","timestamp":1671825778418,"user":{"displayName":"Fabiano Moreira Alves","userId":"09146577383397768685"},"user_tz":180},"id":"PVWw0Wj9PJgA","outputId":"2b07678d-d5b1-4635-c3c0-c25b3b91ae16"},"outputs":[],"source":["import requests\n","import json\n","import pandas as pd\n","from pandas.io.json import json_normalize\n","import numpy as np\n","import geopy\n","from geopy.geocoders import Nominatim\n","from geopy.point import Point\n","from cryptography.fernet import Fernet\n","from datetime import datetime\n","from google.oauth2.service_account import Credentials\n","from google.oauth2 import service_account\n","import google.auth\n","from google.auth.transport.requests import AuthorizedSession\n","from google.cloud import bigquery\n","from google.oauth2 import service_account\n","import pandas_gbq as gbq\n","\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Gerar um token para acessar a API\n","    O token para acessar a API da begrowth é fornecido após cadastrar um\n","    usuário.\n","\n","    Informar os dados Nome e E-mail nos campos full_name e email.\n","    \n","    Após fazer um request, é retornado o usuário e o token para acessar a API.\n","    Por fim, imprime na tela o json obtido."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["headers = {\n","    'accept': 'application/json',\n","    'Content-Type': 'application/json',\n","}\n","\n","json_data = {\n","    'full_name': 'Fabiano Moreira Alves',\n","    'email': 'fabianomalves@proton.me',\n","}\n","\n","access_token = requests.post('https://begrowth.deta.dev/user/', headers=headers, json=json_data)\n","access_token_json = access_token.json()\n","\n","print(access_token_json)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"uzvfZ4d0nd3R"},"source":["## Separando o usuário e o token para acessar a API\n","    Como o request retorna um json(dicionário) é preciso separar o dicionário\n","    e pegar somente a informação do token.\n","    \n","    Após isso, imprime na tela somente o token."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":363,"status":"ok","timestamp":1671825786381,"user":{"displayName":"Fabiano Moreira Alves","userId":"09146577383397768685"},"user_tz":180},"id":"M6FJKmp5ndYr","outputId":"21863d33-2c6c-4cc3-d893-4e8055d478af"},"outputs":[],"source":["# split dictionary into keys and values\n","keys = []\n","values = []\n","items = access_token_json.items()\n","for item in items:\n","    keys.append(item[0]), values.append(item[1])\n"," \n","# printing keys and values separately\n","string_acess_token = str(values[-1])\n","print(string_acess_token)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"oGGQwQKqnsP5"},"source":["## Consumir a api, chamando-a e passando o token adquirido\n","    Concatenando a url https://begrowth.deta.dev/token=access_token, junto do\n","    token obtido é necessário para acessar os dados da API.\n","\n","    Para isso, concatenei a url com o token obtido anteriormente e salvei numa\n","    variável.\n","    \n","    Exibindo a url, concatenando com o token obtido."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":376,"status":"ok","timestamp":1671825950303,"user":{"displayName":"Fabiano Moreira Alves","userId":"09146577383397768685"},"user_tz":180},"id":"qIprVyn6nsky","outputId":"17674d07-665f-41dd-a235-6ec294c45934"},"outputs":[],"source":["url_dev = \"https://begrowth.deta.dev/token=\"\n","url_dev_with_token = url_dev + string_acess_token\n","print(url_dev_with_token)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"eenrX4tjlAY0"},"source":["## Normalizar o json recebido pelo request, inserindo ele num dataframe Pandas\n","    Como os dados do obtidos pelo requests são um json, \n","    foi feita uma \"normalização dos dados e foi inserido num dataframe.\n","\n","    Processo feito para trabalhar melhor com os dados, principalmente com campo\n","    address, que contem outro dicionário dentro da estrutura do json.\n","    \n","    Exibindo as primeiras linhas do dataframe."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4636,"status":"ok","timestamp":1671826012948,"user":{"displayName":"Fabiano Moreira Alves","userId":"09146577383397768685"},"user_tz":180},"id":"ugBTuX254B18","outputId":"ecc8f768-329f-4574-a3d4-420c4e1c3053"},"outputs":[],"source":["data = json.loads(requests.get(url_dev_with_token).text)\n","df_json_normalize = pd.json_normalize(data)\n","df_json_normalize.head()\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"VEGDyuOOWqwn"},"source":["## Procurando linhas duplicadas:\n","    Ao exibir as primeiras linhas do dataframe, já exibiam algumas linhas\n","    duplicadas. \n","    \n","    Filtrando os duplicados pelo id dos usuários e retornando \n","    todos os duplicados."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":354,"status":"ok","timestamp":1671826042149,"user":{"displayName":"Fabiano Moreira Alves","userId":"09146577383397768685"},"user_tz":180},"id":"KktpJsE0r8Ax","outputId":"a95a676b-fd4c-43c6-9e10-7a87a694222c"},"outputs":[],"source":["duplicate_rows = df_json_normalize[df_json_normalize.duplicated(['id', ])]\n","print(duplicate_rows)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"SKKBo_fojIQh"},"source":["## Removendo as linhas duplicadas\n","    Dando um drop nas linhas duplicadas, filtrando pelo 'id' e salvando\n","    em outro dataframe.\n","\n","    Depois exibe somente as linhas distintas."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":389,"status":"ok","timestamp":1671826105536,"user":{"displayName":"Fabiano Moreira Alves","userId":"09146577383397768685"},"user_tz":180},"id":"dmFKglkTh95r","outputId":"0b740df8-0822-4e85-9165-0058ebfc0ec9"},"outputs":[],"source":["df_distinct_id_rows = df_json_normalize.drop_duplicates(subset=['id'])\n","print(df_distinct_id_rows)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"kr7S58dq4B1-"},"source":["## Fazendo um reverse geocoding \n","    Após normalizar os dados, foram criados 3 novos campos, \n","    destrinchando o campo address. \n","\n","    Campos address.geo_latitude, address.geo_longitude, address.country.\n","\n","    Para conseguir a informação do estado, \n","    é necessário o processo de reverse geocoding, \n","    onde pegamos a latitude e longitude e filtramos as informações que queremos,\n","    no caso o estado. \n","    \n","    Porém, verifiquei que os nomes dos estados\n","    apresentam acentos, o que é um problema na hora de fazer os selects.\n","    \n","    Para isso, peguei o campo ISO 3166-2, que é um padrão mundial de siglas\n","    por estados, gerando o padrão BR-UF.\n","    Como teremos os UFs, será melhor para fazer os selects."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create a geocoder object using the Nominatim API\n","geolocator = Nominatim(user_agent=\"my_geocoder_state\")\n","\n","# Define a function to reverse geocode the state\n","def get_state(lat, lng):\n","  # Use the geocoder object to reverse geocode the coordinates\n","  location = geolocator.reverse((lat, lng))\n","  # Extract the state code from the response, using ISO3166-2-lvl4\n","  state = location.raw['address']['ISO3166-2-lvl4']\n","  return state\n","\n","# Apply the function to each row of the DataFrame and store the result in a new column\n","\n","df_distinct_id_rows.loc[:, ['address_state']] = df_distinct_id_rows.apply(lambda x: get_state(x['address.geo_latitude'], x['address.geo_longitude']), axis=1)\n","\n","\n","\n","# Display a resulting DataFrame\n","df_distinct_id_rows.head()\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Salvando o novo dataframe num arquivo csv.\n","    Como o processo de reverse geocodin demora demais, \n","    salvei o dataframe localmente, \n","    para não demorar muito, \n","    caso fosse necessário rodar novamente o script.\n","\n","    Conseguiria trabalhar desse ponto em diante com o arquivo fisico,\n","    caso necessário."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_distinct_id_rows.to_csv('../data_engineer_test/df_distinct_id_rows.csv', index=False)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Read csv file"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_distinct_id_rows = pd.read_csv('../data_engineer_test/df_distinct_id_rows.csv')\n","df_distinct_id_rows.head()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Descriptografar o campo CPF\n","    O campo CPF está criptografado, pela criptografia Fernet.\n","    \n","    Para isso, é necessário usar a chave Fernet, passada por e-mail.\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fernet = Fernet(b'ekkxXo0uHWRkIbHqHrLS4gaMj2hWTYMJyPTAbi9INGI=')\n","\n","df_distinct_id_rows['cpf'] = df_distinct_id_rows['cpf'].apply(lambda x: fernet.decrypt(x.encode()))\n","\n","df_distinct_id_rows.head()\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Salvando o arquivo descriptografado num csv"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","df_distinct_id_rows.to_csv('../data_engineer_test/df_decrypt_cpf.csv', index=False)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Lendo o arquivo csv, cujo cpf foi descriptografado."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_decrypt_cpf = pd.read_csv('../data_engineer_test/df_decrypt_cpf.csv' )\n","df_decrypt_cpf.head()\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Formatando a coluna CPF\n","    Após descriptografar o cpf, a coluna ficou um b de byte, \n","    oriundo da chave de descriptografar.\n","\n","    Fazendo a remoção das informações que são desnecessárias."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_decrypt_cpf['cpf'] = df_decrypt_cpf['cpf'].apply(lambda x: x[2: -1])\n","df_decrypt_cpf.head()\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Salvando o arquivo descriptografado e formatado num csv"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_decrypt_cpf['cpf'] = df_decrypt_cpf['cpf'].astype(str)\n","df_decrypt_cpf.to_csv('../data_engineer_test/df_decrypt_formatting_cpf.csv', index=False)\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Lendo o arquivo csv, descriptografado e formatado e transformando num df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pd.set_option('display.max_rows', 100)\n","df_decrypt_formatting_cpf = pd.read_csv('../data_engineer_test/df_decrypt_formatting_cpf.csv', dtype={'cpf': str})\n","print(df_decrypt_formatting_cpf.head(20))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Removendo o prefixo \"BR-\" da coluna address_state\n","    Para deixar a coluna mais clean, \n","    manter somente as UFs no campo address_state"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_decrypt_formatting_cpf[\"address_state\"] = df_decrypt_formatting_cpf[\"address_state\"].str.replace(\"BR-\", \"\")\n","df_decrypt_formatting_cpf.head()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Inserindo colunas dt_insert e candidate_name\n","    Inserindo as colunas dt_insert e candidate_name\n","    conforme solicitado e prenchendo com um timestamp e o nome."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create a variable now, with the actual timestamp\n","now = datetime.now()\n","\n","# Create new columns\n","df_decrypt_formatting_cpf = df_decrypt_formatting_cpf.assign(\n","    dt_insert=now,\n","    candidate_name='Fabiano Moreira Alves'\n",")\n","\n","df_decrypt_formatting_cpf.head()\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Alterar os nomes das colunas, inserindo um '_' ao invés de '.'\n","    Removendo os pontos dos nomes das colunas e trocando por underscores.\n","    Processo necessário para inseir os dados no Google BigQuery.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_decrypt_formatting_cpf = df_decrypt_formatting_cpf.rename(columns=lambda x: x.replace('.', '_'))\n","\n","df_decrypt_formatting_cpf.head()\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Salvando o dataframe após as transformações."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_decrypt_formatting_cpf['cpf'] = df_decrypt_formatting_cpf['cpf'].astype(str)\n","df_decrypt_formatting_cpf.to_csv('../data_engineer_test/bg_data_enginner_test_fabiano.csv', index=False)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df = pd.read_csv('../data_engineer_test/bg_data_enginner_test_fabiano.csv', dtype={'cpf': str}, )\n","print(df.head(30))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Conectar no big query e fazer um select\n","### Tabela: bg_users.brazilian_state"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","project_id = 'begrowth-user-api-demo'\n","dataset_id = 'bg_users'\n","\n","# Set the path to your service account file\n","service_account_file = '/home/fabiano/Projects/data_engineer_test/svc-data-engineer-test.json'\n","\n","# Load the service account credentials from the file\n","credentials = service_account.Credentials.from_service_account_file(service_account_file)\n","\n","# Create a BigQuery client using your service account credentials\n","client = bigquery.Client(credentials=credentials, project=project_id)\n","\n","sql = \"\"\"\n","SELECT \n","    *\n","FROM \n","begrowth-user-api-demo.bg_users.brazilian_state\n","\"\"\"\n","df = gbq.read_gbq(sql, project_id = project_id, credentials=credentials, progress_bar_type=None)\n","\n","print(df)\n","\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Conectar no big query e fazer um select\n","### Tabela: begrowth-user-api-demo.bg_users.cpf_state"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["project_id = 'begrowth-user-api-demo'\n","dataset_id = 'bg_users'\n","\n","# Set the path to your service account file\n","service_account_file = '/home/fabiano/Projects/data_engineer_test/svc-data-engineer-test.json'\n","\n","# Load the service account credentials from the file\n","credentials = service_account.Credentials.from_service_account_file(service_account_file)\n","\n","# Create a BigQuery client using your service account credentials\n","client = bigquery.Client(credentials=credentials, project=project_id)\n","\n","sql = \"\"\"\n","SELECT \n","    *\n","FROM \n","begrowth-user-api-demo.bg_users.cpf_state\n","\"\"\"\n","df = gbq.read_gbq(sql, project_id = project_id, credentials=credentials, progress_bar_type=None)\n","\n","print(df)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Create a service account with the key provided in email"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"ename":"Forbidden","evalue":"403 GET https://bigquery.googleapis.com/bigquery/v2/projects/begrowth-user-api-demo/datasets/bg_users/tables/bg_data_enginner_test_fabiano_moreira_alves?prettyPrint=false: Access Denied: Table begrowth-user-api-demo:bg_users.bg_data_enginner_test_fabiano_moreira_alves: Permission bigquery.tables.get denied on table begrowth-user-api-demo:bg_users.bg_data_enginner_test_fabiano_moreira_alves (or it may not exist).","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mForbidden\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[40], line 20\u001b[0m\n\u001b[1;32m     16\u001b[0m dataset_id \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mbg_users\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     17\u001b[0m table_id \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mbg_data_enginner_test_fabiano_moreira_alves\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m---> 20\u001b[0m gbq\u001b[39m.\u001b[39;49mto_gbq(df, \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mproject_id\u001b[39m}\u001b[39;49;00m\u001b[39m.\u001b[39;49m\u001b[39m{\u001b[39;49;00mdataset_id\u001b[39m}\u001b[39;49;00m\u001b[39m.\u001b[39;49m\u001b[39m{\u001b[39;49;00mtable_id\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m, project_id\u001b[39m=\u001b[39;49mproject_id, if_exists \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mreplace\u001b[39;49m\u001b[39m'\u001b[39;49m, credentials\u001b[39m=\u001b[39;49mcredentials)\n","File \u001b[0;32m~/Insync/fabiano.moreira.alves@gmail.com/Google Drive/Projects/data_engineer_test/.venv/lib/python3.10/site-packages/pandas_gbq/gbq.py:1157\u001b[0m, in \u001b[0;36mto_gbq\u001b[0;34m(dataframe, destination_table, project_id, chunksize, reauth, if_exists, auth_local_webserver, table_schema, location, progress_bar, credentials, api_method, verbose, private_key)\u001b[0m\n\u001b[1;32m   1151\u001b[0m     table_schema \u001b[39m=\u001b[39m pandas_gbq\u001b[39m.\u001b[39mschema\u001b[39m.\u001b[39mupdate_schema(\n\u001b[1;32m   1152\u001b[0m         default_schema, \u001b[39mdict\u001b[39m(fields\u001b[39m=\u001b[39mtable_schema)\n\u001b[1;32m   1153\u001b[0m     )\n\u001b[1;32m   1155\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1156\u001b[0m     \u001b[39m# Try to get the table\u001b[39;00m\n\u001b[0;32m-> 1157\u001b[0m     table \u001b[39m=\u001b[39m bqclient\u001b[39m.\u001b[39;49mget_table(destination_table_ref)\n\u001b[1;32m   1158\u001b[0m \u001b[39mexcept\u001b[39;00m google_exceptions\u001b[39m.\u001b[39mNotFound:\n\u001b[1;32m   1159\u001b[0m     \u001b[39m# If the table doesn't already exist, create it\u001b[39;00m\n\u001b[1;32m   1160\u001b[0m     table_connector \u001b[39m=\u001b[39m _Table(\n\u001b[1;32m   1161\u001b[0m         project_id_table,\n\u001b[1;32m   1162\u001b[0m         dataset_id,\n\u001b[1;32m   1163\u001b[0m         location\u001b[39m=\u001b[39mlocation,\n\u001b[1;32m   1164\u001b[0m         credentials\u001b[39m=\u001b[39mconnector\u001b[39m.\u001b[39mcredentials,\n\u001b[1;32m   1165\u001b[0m     )\n","File \u001b[0;32m~/Insync/fabiano.moreira.alves@gmail.com/Google Drive/Projects/data_engineer_test/.venv/lib/python3.10/site-packages/google/cloud/bigquery/client.py:1041\u001b[0m, in \u001b[0;36mClient.get_table\u001b[0;34m(self, table, retry, timeout)\u001b[0m\n\u001b[1;32m   1039\u001b[0m path \u001b[39m=\u001b[39m table_ref\u001b[39m.\u001b[39mpath\n\u001b[1;32m   1040\u001b[0m span_attributes \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mpath\u001b[39m\u001b[39m\"\u001b[39m: path}\n\u001b[0;32m-> 1041\u001b[0m api_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_api(\n\u001b[1;32m   1042\u001b[0m     retry,\n\u001b[1;32m   1043\u001b[0m     span_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mBigQuery.getTable\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1044\u001b[0m     span_attributes\u001b[39m=\u001b[39;49mspan_attributes,\n\u001b[1;32m   1045\u001b[0m     method\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mGET\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1046\u001b[0m     path\u001b[39m=\u001b[39;49mpath,\n\u001b[1;32m   1047\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m   1048\u001b[0m )\n\u001b[1;32m   1049\u001b[0m \u001b[39mreturn\u001b[39;00m Table\u001b[39m.\u001b[39mfrom_api_repr(api_response)\n","File \u001b[0;32m~/Insync/fabiano.moreira.alves@gmail.com/Google Drive/Projects/data_engineer_test/.venv/lib/python3.10/site-packages/google/cloud/bigquery/client.py:789\u001b[0m, in \u001b[0;36mClient._call_api\u001b[0;34m(self, retry, span_name, span_attributes, job_ref, headers, **kwargs)\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[39mif\u001b[39;00m span_name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    786\u001b[0m     \u001b[39mwith\u001b[39;00m create_span(\n\u001b[1;32m    787\u001b[0m         name\u001b[39m=\u001b[39mspan_name, attributes\u001b[39m=\u001b[39mspan_attributes, client\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, job_ref\u001b[39m=\u001b[39mjob_ref\n\u001b[1;32m    788\u001b[0m     ):\n\u001b[0;32m--> 789\u001b[0m         \u001b[39mreturn\u001b[39;00m call()\n\u001b[1;32m    791\u001b[0m \u001b[39mreturn\u001b[39;00m call()\n","File \u001b[0;32m~/Insync/fabiano.moreira.alves@gmail.com/Google Drive/Projects/data_engineer_test/.venv/lib/python3.10/site-packages/google/api_core/retry.py:349\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    345\u001b[0m target \u001b[39m=\u001b[39m functools\u001b[39m.\u001b[39mpartial(func, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    346\u001b[0m sleep_generator \u001b[39m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    347\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initial, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maximum, multiplier\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_multiplier\n\u001b[1;32m    348\u001b[0m )\n\u001b[0;32m--> 349\u001b[0m \u001b[39mreturn\u001b[39;00m retry_target(\n\u001b[1;32m    350\u001b[0m     target,\n\u001b[1;32m    351\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predicate,\n\u001b[1;32m    352\u001b[0m     sleep_generator,\n\u001b[1;32m    353\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_timeout,\n\u001b[1;32m    354\u001b[0m     on_error\u001b[39m=\u001b[39;49mon_error,\n\u001b[1;32m    355\u001b[0m )\n","File \u001b[0;32m~/Insync/fabiano.moreira.alves@gmail.com/Google Drive/Projects/data_engineer_test/.venv/lib/python3.10/site-packages/google/api_core/retry.py:191\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[39mfor\u001b[39;00m sleep \u001b[39min\u001b[39;00m sleep_generator:\n\u001b[1;32m    190\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 191\u001b[0m         \u001b[39mreturn\u001b[39;00m target()\n\u001b[1;32m    193\u001b[0m     \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    194\u001b[0m     \u001b[39m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n","File \u001b[0;32m~/Insync/fabiano.moreira.alves@gmail.com/Google Drive/Projects/data_engineer_test/.venv/lib/python3.10/site-packages/google/cloud/_http/__init__.py:494\u001b[0m, in \u001b[0;36mJSONConnection.api_request\u001b[0;34m(self, method, path, query_params, data, content_type, headers, api_base_url, api_version, expect_json, _target_object, timeout, extra_api_info)\u001b[0m\n\u001b[1;32m    482\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_request(\n\u001b[1;32m    483\u001b[0m     method\u001b[39m=\u001b[39mmethod,\n\u001b[1;32m    484\u001b[0m     url\u001b[39m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m     extra_api_info\u001b[39m=\u001b[39mextra_api_info,\n\u001b[1;32m    491\u001b[0m )\n\u001b[1;32m    493\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mstatus_code \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 494\u001b[0m     \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mfrom_http_response(response)\n\u001b[1;32m    496\u001b[0m \u001b[39mif\u001b[39;00m expect_json \u001b[39mand\u001b[39;00m response\u001b[39m.\u001b[39mcontent:\n\u001b[1;32m    497\u001b[0m     \u001b[39mreturn\u001b[39;00m response\u001b[39m.\u001b[39mjson()\n","\u001b[0;31mForbidden\u001b[0m: 403 GET https://bigquery.googleapis.com/bigquery/v2/projects/begrowth-user-api-demo/datasets/bg_users/tables/bg_data_enginner_test_fabiano_moreira_alves?prettyPrint=false: Access Denied: Table begrowth-user-api-demo:bg_users.bg_data_enginner_test_fabiano_moreira_alves: Permission bigquery.tables.get denied on table begrowth-user-api-demo:bg_users.bg_data_enginner_test_fabiano_moreira_alves (or it may not exist)."]}],"source":["df = pd.read_csv('../data_engineer_test/bg_data_enginner_test_fabiano.csv', dtype={'cpf': str})\n","\n","\n","\n","\n","# Set the path to your service account file\n","service_account_file = '/home/fabiano/Projects/data_engineer_test/svc-data-engineer-test.json'\n","\n","# Load the service account credentials from the file\n","credentials = service_account.Credentials.from_service_account_file(service_account_file)\n","\n","# Create a BigQuery client using your service account credentials\n","client = bigquery.Client(credentials=credentials, project=project_id)\n","\n","project_id = 'begrowth-user-api-demo'\n","dataset_id = 'bg_users'\n","table_id = 'bg_data_enginner_test_fabiano_moreira_alves'\n","\n","\n","gbq.to_gbq(df, f\"{project_id}.{dataset_id}.{table_id}\", project_id=project_id, if_exists = 'replace', credentials=credentials)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":".venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"},"vscode":{"interpreter":{"hash":"5b35418006b61e0b8845dba7655e90c821974852f2d4b880fdb488ffc5bd8e57"}}},"nbformat":4,"nbformat_minor":0}
